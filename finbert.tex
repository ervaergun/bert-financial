\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{chapterbib}
\usepackage[sectionbib]{natbib}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%\usepackage{biblatex}
%\addbibresource{projects.bib}


%\title{Predicting Merger Targets and Acquirers from Text}


\title{\vspace{-4cm} Predicting Stock Returns and Risk from Financial Reports with Pretrained Language Models}
\author{}
\date{}

\begin{document}

\maketitle

\section{Abstract}

\section{Introduction and Related Work}

%related work
There are previous methods that use Machine learning to predict stock
markets.~\cite{ding2015} proposes a deep learning method for
event-driven stock market prediction. First, events are extracted from news text, and represented as dense vectors,
trained using a novel neural tensor network. Second, a deep convolutional neural network is used to model both short-term and
long-term influences of events on stock price movements.

The use of robo-readers to analyze news texts is an emerging technology trend in computational finance. In recent
research, a substantial effort has been invested to develop sophisticated financial polarity-lexicons that can be used to
investigate how financial sentiments relate to future company performance. However, based on experience from other
fields, where sentiment analysis is commonly applied, it is well-known
that the overall semantic orientation of a sentence may differ from
the prior polarity of individual words.

% Neural network model
Financial risk, defined as the chance to deviate from return expectations, is most commonly measured
with volatility. Due to its value for investment decision making, volatility prediction is probably
among the most important tasks in finance and risk management. Although evidence exists that enriching purely financial models with natural language
information can improve predictions of volatility, this task is still comparably underexplored. We introduce PRoFET, the
first neural model for volatility prediction jointly exploiting both
semantic language representations and a comprehensive set of financial
features. As language data, we use transcripts from quarterly
recurring events, so-called earnings calls; in these calls, the performance of publicly traded companies is summarized and prognosticated by their management. We show that our
proposed architecture, which models verbal context with an attention mechanism, significantly outperforms the previous state-of-the-art and other strong
baselines. Finally, we visualize this attention mechanism on the token-level, thus aiding interpretability and providing a use case of PRoFET as a tool
for investment decision support~\cite{theil2019}.


\section{Experiments}

There are similar papers in the literature~\cite{kogan2009}. Using BERT models in finance have also been used in the literature~\cite{araci2019, yang2020}
%FinBERT: A Pretrained Language Model for Financial Communications.

We do not have many financial datasets for financial tasks.

We will compare our BERT based method with the following approaches:
\begin{itemize}
\item Baseline method will be volatility prediction based on GARCH similar to~\cite{kogan2009}.
\item SVM-based/Random Forest based volatility prediction as in
  paper~\cite{kogan2009}.
  \item SVM-based/Random Forest based return prediction as in
    paper. Previous papers has not focused on return prediction.
  \item Original BERT trained model.
   \item Elmo-based trained model.
\end{itemize}

One type of evaluation will based Mean squared error~(MSE) based.

Other evaluation type will be based on portfolio construction:
\begin{itemize}
\item Buckets on predicted returns. 
\item Stock portfolios based on Markovitz portfolios based on predicted returns and volatility and covariance between pairs.
\end{itemize}

We will focus on predicting the returns and volatilities for next
quarter, year half and half respectively. Portfolios will be balanced monthly.




Value Investor's club as discussed in~\cite{yang2018}.

\subsection{FiQA}

The provided training dataset for WWW ’18~\cite{maia2018} contains a total of 1,174 examples from news headlines and tweets. Each example contains the sentence and the sentence snippet
associated with the target entity, aspect, and sentiment score. A
sample FiQA entry is shown in~\ref{tab:fiqa_example}. A Level 1 Aspect
label takes on one of $4$ possible labels (Corporate, Economy, Market or Stock), and our Level 2 Aspect label takes on
one of $27$ possible labels (Appointment, Risks, Dividend Policy, Financial, Legal, Volatility, Coverage, Price Action, etc.). The original
dataset contained a small number of multilabel examples, however, we considered this number
too few to train a meaningful multilabel classifier. Thus, we slightly
stray from the original WWW ’18 task for the purpose of this research. Finally, sentiment score takes on a continuous value between $-1$ and $1$ – most negative to most positive.

We can use FiQA dataset for both classification purpose in terms of aspect levels, and regression purpose in terms of sentiment score.

\begin{table}
  \begin{tabular}{|c|c|}
    \hline 
 Sentence & easyJet expects resilient demand to withstand security
            fears. \\ \hline
Aspect Level 1 &  Corporate \\ \hline 
Aspect Level 2 & Risks \\ \hline 
Sentiment Score & 0.165 \\ \hline 
Target & easyJet \\ \hline 
\end{tabular}
\caption{An example entry from FiQA}
\label{tab:fiqa_example}
\end{table}


A large collection of financial reports published annually by publicly-traded companies is employed to conduct our experiments;
moreover, two analytical techniques – regression and ranking methods –
are applied to conduct these analyses~\cite{xxx}.

The authors in~\cite{steven2017} used a dataset of more than 900,000 news stories to test
whether news can predict stock returns. They measured sentiment with a
proprietary Thomson Reuters neural network and found that daily news
predicts stock returns for only one to two days, confirming previous
research. Weekly news, however, predicts stock returns for one
quarter. Positive news stories increase stock returns quickly, but
negative stories receive a long-delayed reaction. Much of the delayed
response to news occurs around the subsequent earnings announcement.

Reuter's and Bloomberg dataset: Datasets are in Emre's email.
\url{https://github.com/philipperemy/financial-news-dataset}

Reuter's news dataset:
\url{https://github.com/duynht/financial-news-dataset}


\textbf{NLTK's corpus}
\url{https://www.kaggle.com/boldy717/reutersnltk#__sid=js0}


\textbf{Fed Meeting Notes}
\url{https://fraser.stlouisfed.org/title/federal-open-market-committee-meeting-minutes-transcripts-documents-677?browse=2020s}

FOMC Statements Scraper
https://github.com/souljourner/FOMC-Statements-Minutes-Scraper
Some cleaned transcripts
https://github.com/ali-wetrill/FOMCTranscriptAnalysis

We can predict volatility or whether volatility will go up or down of the following instruments:
\begin{itemize}
\item S\&P 500
\item 13-week Treasury Bills
\item 10-year Treasury Notes
\end{itemize}

Another source for datasets: \url{https://rstudio-pubs-static.s3.amazonaws.com/495650_c9c874694f164fb5948031801079157f.html#3_data}


We mainly focus on predicting the change of the Standard \& Poor’s 500 stock (S\&P 500) index,
obtaining indices and stock price data from Yahoo Finance. Standard \& Poor’s 500 is a stock market index based
on the market capitalizations of 500 large companies having common stock listed on the NYSE or NASDAQ.


\url{https://sraf.nd.edu/textual-analysis/resources/#LM%20Sentiment%20Word%20Lists}

Finally,
the texts are stemmed using the Porter stemmer.


10K dataset together with volatilities
http://ifs.tuwien.ac.at/~admire/financialvolatility/




% well-written
Recently, unsupervised pre-training of language models on large corpora has significantly improved the performance of many NLP tasks. The
language models are pretained on generic corpora such as Wikipedia. However, sentiment analysis
is a strongly domain dependent task. Financial sector has accumulated large scale of text of financial and business communications. Therefore,
leveraging the success of unsupervised pretraining and large amount of
financial text could potentially benefit wide range of financial applications.


Predicting Risk from Financial Reports with Regression
is a related paper.


Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we
propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel
techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively,
and the attention weights among words are computed using disentangled
matrices on their contents and relative positions. Second, an enhanced mask decoder is used
to replace the output softmax layer to predict the masked tokens for model pretraining. We show that these two techniques significantly improve the efficiency of
model pre-training and performance of downstream tasks. Compared to RoBERTaLarge, a DeBERTa model trained on half of the training data performs consistently
better on a wide range of NLP tasks, achieving improvements on MNLI.

Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks.

In this paper, we use variants of BERT. We propose a new model
architecture DeBERTa (Decoding-enhanced BERT with disentangled
attention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively,
and the attention weights among words are computed using disentangled
matrices on their contents and relative positions. Second, an enhanced mask decoder is used
to replace the output softmax layer to predict the masked tokens for
model pretraining.

We show that these two techniques significantly improve the efficiency of
model pre-training and performance of downstream tasks. In financial
domain, the same is observed.



BERT and its variants have significantly enhanced word vector
representation. Here, we will focus on specific BERT application on financial
datasets.

Our approach will be based on \url{https://github.com/microsoft/DeBERTa}

Sample datasets are:
\begin{itemize}
\item FIQA: Financial Opinion Mining and Question Answering \url{https://sites.google.com/view/fiqa/home}
\vspace{0.1cm}
\item Financial Phrasebank:
\end{itemize}


http://www.cs.cmu.edu/~ark/10K/data/
Metadata var

10K downloads: https://pypi.org/project/sec-edgar-downloader/. Filing
date is in each text file.

extract MDA and tokenize new files in Noah's website can be used to clean the dataset.
CIK Ticker Mapping: https://www.sec.gov/include/ticker.txt

Ticker price: Yahoo finance download https://towardsdatascience.com/downloading-historical-stock-prices-in-python-93f85f059c1f


This text regression problem has been discussed before.



\textbf{Corporate Reports 10-K \& 10-Q} The most important text data in finance and business communication is corporate report. In the United States,
the Securities Exchange Commission (SEC) mandates all publicly traded companies to file annual
reports, known as Form 10-K, and quarterly reports, known as Form 10-Q. This document provides a comprehensive overview of the company’s
business and financial condition. Laws and regulations prohibit companies from making materially
false or misleading statements in the 10-Ks. The
Form 10-Ks and 10-Qs are publicly available and can be accesses from
SEC website. We obtain 60,490 Form 10-Ks and 142,622
Form 10-Qs of Russell 3000 firms during 1994 and
2019 from SEC website. We only include sections that are textual components, such as Item 1 (Business) in 10-Ks, Item 1A (Risk Factors) in both 10-
Ks and 10-Qs and Item 7 (Managements Discussion and Analysis) in 10-Ks.


\bibliographystyle{plain}
\bibliography{finbert}


\end{document}
